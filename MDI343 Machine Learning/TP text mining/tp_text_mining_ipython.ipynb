{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Text Mining, Naive Bayes Classifier \n",
    "Mohamed AL ANI, le 09/12/2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing packages that we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import vocabulary\n",
    "from scipy.sparse import csr_matrix\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk \n",
    "import re\n",
    "\n",
    "#Sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "2000 documents\n",
      "Nombre d'avis positifs : 1000 \n",
      "Nombre d'avis négatifs : 1000 \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"Loading dataset\")\n",
    "\n",
    "from glob import glob\n",
    "filenames_neg = sorted(glob(op.join('data', 'imdb1', 'neg', '*.txt')))\n",
    "filenames_pos = sorted(glob(op.join('data', 'imdb1', 'pos', '*.txt')))\n",
    "\n",
    "texts_neg = [open(f).read() for f in filenames_neg]\n",
    "texts_pos = [open(f).read() for f in filenames_pos]\n",
    "\n",
    "#On charge nos stop words dans une liste\n",
    "stopWordsList = open(\"data/english.stop\").read().split(\"\\n\")\n",
    "\n",
    "texts = texts_neg + texts_pos\n",
    "y = np.ones(len(texts), dtype=np.int)\n",
    "y[:len(texts_neg)] = 0.\n",
    "y[len(texts_neg):] = 1.\n",
    "\n",
    "print(\"%d documents\" % len(texts))\n",
    "print(\"Nombre d'avis positifs : %d \" %len(texts_neg))\n",
    "print(\"Nombre d'avis négatifs : %d \" %len(texts_pos))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#On crée une fonction qui récupère le vocabulaire, séparément de count_words pour ne pas avoir \n",
    "# à faire des calculs inutiles lorsque l'on veut que le vocabulaire et non la matrice de mots / occurences\n",
    "\n",
    "def getVocabulary(texts, stopWords): \n",
    "    '''getVocabulary : crée une liste de mots unique dans une liste de texte\n",
    "    \n",
    "    Parameters \n",
    "    ----------\n",
    "    texts : une liste de string\n",
    "    stopWords : Un booléan permettant d'indiquer si l'on veut supprimer de notre analyse les stop words \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Liste de mots uniques\n",
    "    '''\n",
    "    words = set()\n",
    "    if stopWords == True :\n",
    "        for text in texts:\n",
    "            text.replace(\"\\n\", \"\")\n",
    "            for item in text.split(\" \"):\n",
    "                if item not in stopWordsList and len(item)!=1:\n",
    "                    words.add(item)\n",
    "        return words\n",
    "\n",
    "    else : \n",
    "        for text in texts:\n",
    "            text.replace(\"\\n\", \"\")\n",
    "            for item in text.split(\" \"):\n",
    "                words.add(item)\n",
    "        return words\n",
    "\n",
    "def count_words(texts):\n",
    "    \"\"\"Vectorize text : return count of each word in the text snippets\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : list of str\n",
    "        The texts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vocabulary : dict\n",
    "        A dictionary that points to an index in counts for each word.\n",
    "    counts : ndarray, shape (n_samples, n_features)\n",
    "        The counts of each word in each text.\n",
    "        n_samples == number of documents.\n",
    "        n_features == number of words in vocabulary.\n",
    "    \"\"\"\n",
    "    \n",
    "    #We us a csr_matrix for optimality reasons \n",
    "    indptr = [0]\n",
    "    indices = []\n",
    "    data = []\n",
    "    words = set()\n",
    "    vocabulary = {}\n",
    "    for text in texts:\n",
    "        for term in text.split(\" \"):\n",
    "            index = vocabulary.setdefault(term, len(vocabulary))\n",
    "            indices.append(index)\n",
    "            data.append(1)\n",
    "            words.add(term)\n",
    "        indptr.append(len(indices))\n",
    "    return (csr_matrix((data, indices, indptr), dtype=np.int8).toarray(), vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of created matrix data : \n",
      "(2000, 56199)\n",
      "Wall time: 1.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"shape of created matrix data : \")\n",
    "data, voc = count_words(texts)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on ratings : \n",
    "- 5 stars system : \n",
    "    - 3.5/5 and higher are considered positive\n",
    "    - 2.5/5 and below are considered negative\n",
    "- 4 stars system :\n",
    "    - 3/4 and higher are considered positive\n",
    "    - 2/4 and below are considered negative\n",
    "- letter grade system : \n",
    "    - B or above is considered positive\n",
    "    - C- or below is considered negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 : Implementation of NB : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NB(BaseEstimator, ClassifierMixin):\n",
    "    ''' class NB : implémentation du modèle Naive Bayes Classifier\n",
    "    \n",
    "    attributs\n",
    "    ------------\n",
    "    stopWords (bool) : On indique si on veut un vocabulaire sans stop words\n",
    "    prior : (c) np.array, probability of finding c value in y\n",
    "    V : (v) list, vocabulary\n",
    "    condprob : (c, v) matrix np.array, probability of finding a word for each class\n",
    "    dico_index_words : (String : int) dictionnary of words -> index\n",
    "    \n",
    "    \n",
    "    methods \n",
    "    -------\n",
    "    fit : apprentissage\n",
    "    predict : prédiction \n",
    "    score : score d'accuracy du modèle\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, stopWords=True):\n",
    "        self.stopWords = stopWords \n",
    "\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''fit apprentissage du NB\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : (n,p) matrix, numpy array\n",
    "        y : (n) list or numpy array\n",
    "\n",
    "        '''\n",
    "        \n",
    "        #Getting the vocabulary\n",
    "        V = getVocabulary(texts, self.stopWords)\n",
    "        N = len(y)\n",
    "        prior = np.zeros(len(np.unique(y)))\n",
    "        condprob = np.zeros((len(V), len(np.unique(y))))\n",
    "\n",
    "        for c in np.unique(y):\n",
    "            prior[c] = np.sum([y==c])/N\n",
    "            textc = np.array([X])[:,y==c][0]\n",
    "            \n",
    "            #Concatening all texts\n",
    "            text = \" \".join(textc)\n",
    "            \n",
    "            #Word count\n",
    "            textSplit = text.split(\" \")\n",
    "            dico = {}\n",
    "            for word in textSplit:\n",
    "                if word in dico:\n",
    "                    dico[word] +=1\n",
    "                else : \n",
    "                    dico[word] = 0\n",
    "            \n",
    "            sumValues = float(np.sum(list(dico.values())))\n",
    "            dico_index_words = {}\n",
    "            \n",
    "            #Computation of condprob matrix\n",
    "            for i, word in enumerate(V):\n",
    "                try :\n",
    "                    condprob[i,c] = (dico[word]+1) / sumValues\n",
    "                except : \n",
    "                    condprob[i,c] = 1 / sumValues\n",
    "                    \n",
    "                dico_index_words[word] = i\n",
    "\n",
    "        self.V = V\n",
    "        self.prior = prior\n",
    "        self.condprob = condprob\n",
    "        self.dico_index_words = dico_index_words\n",
    "\n",
    "    def predict(self, X):\n",
    "        prediction = np.zeros(len(X))\n",
    "        \n",
    "        #We iterate over all the documents in the list\n",
    "        for i,doc in enumerate(X): \n",
    "            V = set()\n",
    "            doc = doc.replace(\"\\n\", \"\")\n",
    "            \n",
    "            #Creation of a dictionary for each doc\n",
    "            for word in doc.split(\" \"):\n",
    "                V.add(word)\n",
    "            score = np.zeros(len(np.unique(y)))\n",
    "            for c in np.unique(y): \n",
    "                score[c] = np.log(self.prior[c])\n",
    "                for word in V: \n",
    "                    if word in self.dico_index_words:\n",
    "                        score[c] += np.log(self.condprob[self.dico_index_words[word],c])\n",
    "                        \n",
    "            prediction[i] = np.argmax(score)\n",
    "        return (prediction)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X)\n",
    "        return np.mean( pred[:] == y[:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 : Evaluation des performances en cross validation  5 folds : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score brute, sans CV : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.822\n",
      "Wall time: 3.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb = NB(stopWords=False)\n",
    "nb.fit(texts[::2], y[::2])\n",
    "print(\"Accuracy : %0.3f\" %nb.score(texts[1::2], y[1::2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec CV = 5 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score and 95% conf intervalle : \n",
      "Accuracy: 0.81 (+/- 0.02)\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(nb, texts, y, cv=5)\n",
    "print(\"mean score and 95% conf intervalle : \")\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 : idem en ignorant les stop words :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : \n",
      "0.824\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb = NB(stopWords=True)\n",
    "nb.fit(texts[::2], y[::2])\n",
    "print(\"Accuracy : \")\n",
    "print(nb.score(texts[1::2], y[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score and 95% conf intervalle : \n",
      "Accuracy: 0.83 (+/- 0.03)\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(nb, texts, y, cv=5)\n",
    "print(\"mean score and 95% conf intervalle : \")\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On gagne ainsi 2% en accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Mining and Scikitlearn  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a new tokenizer function to ignore useless characters, then we write a regex (inspired by the sources code) to replace all characters that don't correspond to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_tokenizer(s):\n",
    "    prog = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "    return prog.findall(s.replace(\"\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use \"countvectorizer\" that basically will do a word count and some preprocessing on the text. We have tried with different parameters. First we try with an analysis on words with a 2-gram methods. Also we consider only words that have more than 10 occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score and 95% conf intervalle : \n",
      "Accuracy: 0.826 (+/- 0.0000)\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MNB = MultinomialNB()\n",
    "\n",
    "#We use a Pipeline to sum up all the transformation : \n",
    "pipeline = Pipeline([('count', CountVectorizer(analyzer='word', min_df = 10, \\\n",
    "                                               ngram_range=(1,2), stop_words='english', \\\n",
    "                                               tokenizer = my_tokenizer,\\\n",
    "                                              )),\\\n",
    "                     ('MNB', MNB)])\n",
    "\n",
    "scores = cross_val_score(pipeline, texts, y, cv=5).mean()\n",
    "print(\"mean score and 95% conf intervalle : \")\n",
    "print(\"Accuracy: %0.3f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a better accuracy and a better boundary confidence without even using the vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now working on characters 3-7gram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score and 95% conf intervalle : \n",
      "Accuracy: 0.83 (+/- 0.00)\n",
      "Wall time: 4min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = Pipeline([('count', CountVectorizer(analyzer='char', min_df = 10, \\\n",
    "                                               ngram_range=(3,7), stop_words='english', \\\n",
    "                                               tokenizer = my_tokenizer,\\\n",
    "                                              )),\\\n",
    "                     ('MNB', MNB)])\n",
    "\n",
    "scores = cross_val_score(pipeline, texts, y, cv=5).mean()\n",
    "print(\"mean score and 95% conf intervalle : \")\n",
    "print(\"Accuracy: %0.3f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a GridSearchCV on different values of C for a logistic regression and a LinearSVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score : 0.844\n",
      "best param : \n",
      "{'clf': LinearSVC(C=0.001, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0), 'clf__C': 0.001}\n",
      "cv results\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svc = LinearSVC()\n",
    "pipeline = Pipeline([('count', CountVectorizer(analyzer='word', min_df = 10, \\\n",
    "                                               ngram_range=(1,2), stop_words='english', \\\n",
    "                                               tokenizer = my_tokenizer,\\\n",
    "                                              )),\\\n",
    "                     ('clf', svc)])\n",
    "\n",
    "params = dict(clf=[LinearSVC(), LogisticRegression()],\n",
    "              clf__C=[0.0001, 0.001, 0.01])\n",
    "\n",
    "clf = GridSearchCV(pipeline, param_grid = params, cv=5)\n",
    "clf.fit(texts, y)\n",
    "print(\"best score : %0.3f\" %clf.best_score_)\n",
    "print(\"best params : \")\n",
    "print(clf.best_params_ )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we got a better CV score and we print out the best model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try with TfidfVectorizer that will basically transform the wordcount into frequences of words in the text :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score and 95% conf intervalle : \n",
      "Accuracy: 0.856 (+/- 0.0000)\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svc = LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
    "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
    "     verbose=0)\n",
    "\n",
    "pipeline = Pipeline([('count', TfidfVectorizer(analyzer='word', min_df = 10, \\\n",
    "                                               ngram_range=(1,2), stop_words='english', \\\n",
    "                                               tokenizer = my_tokenizer,\\\n",
    "                                              )),\\\n",
    "                     ('clf', svc)])\n",
    "\n",
    "\n",
    "\n",
    "scores = cross_val_score(pipeline, texts, y, cv=5).mean()\n",
    "\n",
    "print(\"mean score and 95% conf intervalle : \")\n",
    "print(\"Accuracy: %0.3f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 + 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "To understand how pos_tag and stemmer works, we tried on a small example : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old text : \n",
      "['Although', 'when', 'He', 'was', 'has', 'liked', 'liking', 'big', 'apples', 'prettier', 'pretty', 'biggest', 'banana', 'carefully']\n",
      "\n",
      "tags we get : \n",
      "[('Although', 'IN'), ('when', 'WRB'), ('He', 'PRP'), ('was', 'VBD'), ('has', 'VBZ'), ('liked', 'VBN'), ('liking', 'VBG'), ('big', 'JJ'), ('apples', 'NNS'), ('prettier', 'VBP'), ('pretty', 'RB'), ('biggest', 'JJS'), ('banana', 'NN'), ('carefully', 'RB')]\n",
      "\n",
      " new text : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'was has like like big appl prettier biggest banana'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"Although when He was has liked liking big apples prettier pretty biggest banana carefully\".split(\" \")\n",
    "print(\"old text : \")\n",
    "print(a)\n",
    "print()\n",
    "print(\"tags we get : \")\n",
    "print(nltk.pos_tag(a))\n",
    "print(\"\\n new text : \")\n",
    "\" \".join([stemmer.stem(word[0]) for word in nltk.pos_tag(a) if word[1] in to_keep])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a list of pos_tags to keep and transform our old texts into new texts with the stemmer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************\n",
      "old text\n",
      "****************\n",
      "the happy bastard's quick movie review \n",
      "damn that y2k bug . \n",
      "it's got a head start in this movie starring jamie lee curtis and another baldwin brother ( william this time ) in a story regarding a crew of a tugboat that comes across a deserted russian tech ship that has a strangeness to it when they kick the power back on . \n",
      "little do they know the power within . . . \n",
      "going for the gore and bringing on a few action sequences here and there , virus still feels very empty , like a movie going for all flash and no substance . \n",
      "we don't know why the crew was really out in the middle of nowhere , we don't know the origin of what took over the ship ( just that a big pink flashy thing hit the mir ) , and , of course , we don't know why donald sutherland is stumbling around drunkenly throughout . \n",
      "here , it's just \" hey , let's chase these people around with some robots \" . \n",
      "the acting is below average , even from the likes of curtis . \n",
      "you're more likely to get a kick out of her work in halloween h20 . \n",
      "sutherland is wasted and baldwin , well , he's acting like a baldwin , of course . \n",
      "the real star here are stan winston's robot design , some schnazzy cgi , and the occasional good gore shot , like picking into someone's brain . \n",
      "so , if robots and body parts really turn you on , here's your movie . \n",
      "otherwise , it's pretty much a sunken ship of a movie . \n",
      "\n",
      "****************\n",
      "new text\n",
      "****************\n",
      "happi bastard quick movi review damn y2k bug it got head start movi star jami lee curti baldwin brother time stori regard crew tugboat come desert russian tech ship has strang kick power littl do know power go gore bring few action sequenc virus feel empti movi go flash substanc don't know crew was middl don't know origin took ship big pink flashi thing hit mir cours don't know donald sutherland is stumbl it \" hey let chase peopl robot \" act is below averag like curti like get kick work halloween h20 sutherland is wast baldwin he act baldwin cours real star are stan winston robot design schnazzi cgi occasion good gore shot pick someon brain robot bodi part turn here movi it sunken ship movi\n",
      "Wall time: 582 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# nltk.help.upenn_tagset() to get list of different tags\n",
    "\n",
    "to_keep = [\"NN\", \"NNP\", \"NNPS\", \"NNS\", \"VBG\", \"VBN\", \"VBD\", \"VBP\", \\\n",
    "           \"VBZ\", \"VB\", \"JJ\", 'JJR', 'JJS']\n",
    "\n",
    "print(\"****************\")\n",
    "print(\"old text\")\n",
    "print(\"****************\")\n",
    "print(texts[1])\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "newTexts = []\n",
    "for text in texts[:2]: \n",
    "    textSplit = text.replace(\"\\n\", \"\").split()\n",
    "    temp = \" \".join([stemmer.stem(word[0]) for word in nltk.pos_tag(textSplit) if word[1] in to_keep])\n",
    "    newTexts.append(temp)\n",
    "print(\"****************\")\n",
    "print(\"new text\")\n",
    "print(\"****************\")\n",
    "print(newTexts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test d'un modèle sur les nouveaux textes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new tokenizer with the stemmer and the pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_new_tokenizer(s):\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    temp = \" \".join([stemmer.stem(word[0]) for word in nltk.pos_tag(s.split()) if word[1] in to_keep])\n",
    "    prog = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "    return prog.findall(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try one last model of LinearSVC with the best model found previously and our new tokenizer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score and 95% conf intervalle : \n",
      "Accuracy: 0.840 (+/- 0.0000)\n",
      "Wall time: 9min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lsvc = LinearSVC(C=0.001, class_weight=None, dual=True, fit_intercept=True,\n",
    "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
    "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
    "     verbose=0)\n",
    "\n",
    "pipeline = Pipeline([('count', CountVectorizer(analyzer='word', min_df = 5, \\\n",
    "                                               ngram_range=(1,2), stop_words='english', \\\n",
    "                                               tokenizer = my_new_tokenizer,\\\n",
    "                                              )),\\\n",
    "                     ('lsvc', lsvc)])\n",
    "\n",
    "scores = cross_val_score(pipeline, texts, y, cv=5).mean()\n",
    "\n",
    "print(\"mean score and 95% conf intervalle : \")\n",
    "print(\"Accuracy: %0.3f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we don't get a better score... Maybe we should recreate a GridSearchCV for the new data we get out of the tokenizer function.\n",
    "However, the fitting took almost 10 minutes so we won't do that here. Especially knowing that we already have quite a good score."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
